Multi-Grid (MG) solvers are a class of linear methods~\cite{Hackbusch1991} that emerged in the 80's to increase the convergence rate of more classical iterative methods. 
They became even more important with the advent of very complex scientific applications~\cite{Ashby1996}, which required very powerful linear solvers. 
The usage of MG solvers has become a common practice in today's parallel systems due to the good scalability properties this methods display, which have been detailedly analyzed and modeled~\cite{Gahvari11}.
Also, MG solvers have been reported to display more robustness against silent data corruptions than traditional iterative methods deployed over a single grid~\cite{Casas12}, which also implies they behave well under reduced accuracy scenarios.

Multi-Grid algorithms rely on a grid of evaluation points that discretize the domain of a continuous differential equation.
Typically, MG schemes are defined by coarsening a fine-grain grid until reaching a small set of evaluation points where a direct method can be applied.
%This grid is represented using different granularity levels that are used to determine a solution on the inaccurate and coarse grids.
Solutions obtained on the inaccurate and coarse grids are used on the more accurate and fine-grain levels to accelerate the process of obtaining the final solution of the system. 
%For example, if we want to solve an equation of the form:
%\[ -u^{''}(x)+au(x) = f(x),\quad 0<x<1, \quad u(0)=u(1)=0, \]
%where $a$ is some constant, $f$ a function and $u$ an unkown function, we can transform it into a discrete problem by selecting $N$ evaluation points $x_1,\dots,x_N$ and using taylor expansion to express the second derivative term $u^{''}(x_i)$ as a weighted sum of $u(x_j)$ for some values of $j$. 
%Then
%to define coarser grids, a simple way to do it is to divide the number of evaluation points and transform the original equation into another discrete problem (thus using evaluation points $x_1,x_3,\dots,x_N$). 
%Typically, multi-grid schemes are defined by coarsening a fine-grain grid until reaching a small enough set of evaluation points on which a direct solve would be fast.
Multi-grid solvers typically consist of three phases: The \textit{Relaxation}, \textit{Restriction} and \textit{Interpolation} phases.
The relaxation phase applies a few steps of
an iterative solver like Jacobi or Gauss-Seidel at a certain coarseness level. 
The restriction phase propagates the algorithmic state to a coarser grid by means of linear transformations while the interpolation phase
maps the coarser estimate to the finer version and adjusts the current solution x with the new error information.

One common way of orchestrating a Multi-Grid Solver execution is via a V-cycle where we first iterate on the finest grid, then the second finest grid and so on until reaching
the coarsest grid where a direct solve is used instead of an iterative method as the problem size has become smaller. 
Then we iterate again on all the other grids in the reverse order to have a solution expressed with the initial fineness of the grid.
Different parameters, such as the iterative method used at each step or the fineness of the grid and the previously mentioned cycle shape, affect the convergence rate of the algorithm.

%Typically, multi-grid schemes are defined by coarsening a fine-grain grid until reaching a small enough set of evaluation points on which a direct solve would be fast. 
%Multi-grid solvers then perform several steps of an iterative method like Jacobi~\cite{} or Gauss-Seidel~\cite{} switching between the different grids by interpolating or restricting the solution of the previous step.
%More precisely, a multi-grid algorithm has a parameter which is the cycle shape.
%The cycle shape determines in which order and on which coarsening of the grid an iterative method is used. The classical cycle shape is the V-cycle where we first iterate on the finest grid, then the second finest grid and so on until reaching
%the coarsest grid where a direct solve is used instead of an iterative method as the problem size has become smaller. Then we iterate again on all the other grids in the reverse order to have a solution expressed with the initial fineness of the grid.
%Different parameters, such as the iterative method used at each step or the fineness of the grid and the previously mentioned cycle shape, affect the convergence rate of the algorithm. For example, using a grid with only a few
%evaluation points decreases the execution time but deteriotates the accuracy of the final result. In the other way, it is possible to increase the quality of the result by using a finer
%grid but at the cost of a performance degradation.

In this context, this paper investigates different trade-offs between accuracy and execution time for multi-grid algorithms. 
This paper focuses its effort on one of the most popular parallel implementation of a multi-grid solver,
the BoomerAMG~\cite{boomerAMG}, implemented in the HYPRE library~\cite{Falgout2002}. 
This paper makes the following contributions beyond the state-of-the-art:

\begin{itemize}
\item We evaluate the impact of parameters of the solver such as the shape of cycles in the grid and the
number of iterations. 
\item We describe a particular cycle that is proved to be at least as efficient as the original algorithm. 
\item Then we investigate how changing the bit-width of some values makes the execution time vary with the maximum accuracy reachable.
\item We give an algorithm that dynamically changes the bit-width of the variables to reduce by 15\% the execution
time needed to reach a same-quality result as the original algorithm (which uses only double-precision floating points) and reducing up to 30\% the execution time for smaller accuracies.
\end{itemize}